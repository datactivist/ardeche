[
["index.html", "Rapport sur l’open data Introduction", " Rapport sur l’open data Samuel Goëta (Datactivist) pour le Conseil départemental de l’Ardèche 2019-12-15 Introduction Ce rapport vise à expliquer les essentiels d’une démarche d’ouverture des données et à décrire les facteurs de succès d’un projet d’open data. C’est un document à visée pédagogique qui, sans entrer dans les détails du contexte institutionnel et des spécificités de chaque jeu de données, permet d’établir un niveau commun de compréhension pour les acteurs de l’ouverture des données en Ardèche. Il repose sur des sources publiques qui sont référencées dans le document, elles sont autant de prolongements pour cette introduction à l’ouverture des données. Dans la première partie, le rapport présente les grands principes internationaux de l’ouverture des données et retrace quelques uns des jalons de l’émergence de l’open data. On y découvre quelques uns des acteurs à l’origine de l’ouverture des données et les principes qui y ont été formulés. La deuxième partie aborde le contexte juridique de l’ouverture des données en France. Elle remonte aux origines de l’open data dans le droit d’accès et de réutilisation des informations publiques pour montrer la continuité avec le principe d’ouverture des données par défaut prévu par la loi pour une république numérique. La troisième partie s’intéresse aux bénéfices organisationnels, informationnels, politiques et économiques de l’ouverture des données. Elle insiste sur les bénéfices immédiats d’une démarche d’open data sans se concentrer uniquement sur le volet économique comme on peut le lire souvent dans la littérature. Enfin, la quatrième partie présente quelques uns des facteurs de succès d’une politique d’open data : obtenir un soutien au plus haut niveau, configurer l’organisation pour l’ouverture, faciliter la découverte et l’utilisation des données, rester à l’écoute et interagir avec les usagers. Ce rapport est une première version, n’hésitez à nous faire parvenir vos retours à l’adresse suivante : samuel@datactivi.st. "],
["partie1.html", "Chapitre 1 Les grands principes d’une démarche d’open data 1.1 Aux origines de l’ouverture des données : retours sur quelques grandes dates fondatrices 1.2 Revue des grands principes de l’ouverture des données", " Chapitre 1 Les grands principes d’une démarche d’open data Comme nous allons le voir dans cette première partie, le cadre juridique de l’ouverture des données repose sur des racines anciennnes mais l’open data en tant que tel est apparu récemment, il y a moins de 10 ans, avec des grands principes qui se sont consolidés avec le temps. Dans cette première partie, nous allons revoir ensemble les grands principes de l’open data : leurs origines, leur adaptation en France et les bénéfices pour une collectivité à les adopter. 1.1 Aux origines de l’ouverture des données : retours sur quelques grandes dates fondatrices En cinq épisodes, revenons sur les principaux moments de définition des grands principes internationaux de l’open data. Cette partie permettra de replacer l’open data dans son contexte d’apparition, de mieux connaitre les acteurs à l’origine des grands principes et de comprendre les textes de référence de l’ouverture des données. Nous résumerons les grands principes de l’ouverture des données dans la partie suivante. Avant de revenir sur ces différents épisodes, il faut rappeler que le terme d’open data a des origines plus anciennes que la dernière décennie sur laquelle nous allons nous concentrer ici. Le terme est apparu pour la première fois dans les années 1970 dans les accords qu’a signés la NASA avec des pays partenaires en vue du partage de données satellitaires. C’est en 1995 qu’on en voit le premier usage public aux Etats-Unis dans un rapport de la National Academy of Science intitutlé On the Full and Open Exchange of Scientific Data. 1.1.1 2005 : Open Definition, la définition juridique des droits de l’usager du savoir ouvert En août 2005,le chercheur en économie Rufus Pollock, fondateur de l’Open Knowledge Foundation (OKFN), une organisation à but non lucratif qui vise à “promouvoir l’ouverture de toutes les formes de savoir”, invitait les premiers membres de l’OKFN et son réseau de partenaires à adopter collectivement une définition du savoir ouvert. Dans son appel à commentaire (Request for Comments), Pollock souhaitait décliner une série de conditions essentiellement juridiques permettant d’établir qu’un savoir est ouvert. La définition devait aussi servir à énumérer les licences ouvertes spécifiques au savoir et à fédérer des disciplines éparses. Cette définition se fonde directement de l’expérience du mouvement de l’open source, l’ouverture du code informatique, une généalogie clairement affirmée dans le texte de l’Open Definition qui crédite l’Open Source Definition comme la ressource essentielle qui a servi à la rédaction de la définition mais aussi à forger l’idée même d’ouverture. Cet effort de définition s’inscrit aussi dans le prolongement du travail de Creative Commons qui a défini une série de licences assorties à des droits et devoirs des usagers d’un savoir ouvert. Pour la résumer en quelques mots, l’Open Definition quelques années après sa publication) décline les conditions de l’ouverture du savoir. Cette définition utilise la notion de savoir pour désigner un domaine très large, qui rassemble des objets informationnels très différents (donnée, document, contenu, œuvre, article…) Sans entrer dans le détail de chacune des clauses, l’Open Definition exclut les licences qui « discriminent » selon les types d’usagers ou la finalité de la réutilisation. Elle demande d’accorder trois droits fondamentaux (utiliser, réutiliser, redistribuer) et autorise à contraindre les réutilisateurs à deux exigences possibles : la citation de la source et le partage des modifications de l’œuvre avec la même licence (clause de share alike). En posant la base d’un élargissement de l’open source au savoir, l’Open Definition a constitué une ressource précieuse pour l’ouverture des données publiques. Elle a établi des critères essentiellement juridiques qui caractérisent l’ouverture en termes de droits des usagers sans préjuger du type de savoir concerné. Cet effort de définition s’est inscrit aussi dans le prolongement du travail de Creative Commons qui a défini une série de licences assorties à des droits et devoirs des usagers d’un savoir ouvert. Aller plus loin : lire l’Open Definition. 1.1.2 2007 : la rencontre dite de Sebastopol, la définition des grands principes de l’open data Après avoir découvert les fondements juridiques de l’ouverture des données avec l’Open Definition, nous partons maintenant aux Etats Unis à la rencontre de ceux qui ont défini les principes encore aujourd’hui en vigueur de l’open data. Le 22 octobre 2007, une invitation est envoyée aux membres d’un groupe de travail sur l’Open Government pour une rencontre les 7 et 8 décembre 2007 à Sebastopol en Californie au sein des locaux de la maison d’édition O’Reilly. Les organisateurs de cette rencontre sont Carl Malamud qui dirige le site associatif PublicRessource.org et Tim O’Reilly, le directeur de la maison d’édition O’Reilly spécialisée dans les sujets technologiques et l’édition électronique ouverte. Dans le texte de l’invitation, les deux organisateurs se sont fixés pour ambition de lister dix principes de l’open government afin que les candidats à l’élection du président des États-Unis suivent leurs recommandations.Trente participants sélectionnés par les organisateurs en fonction de leur affiliation à une organisation qui demande, ouvre ou réutilise des données ont accepté l’invitation de Malamud et O’Reilly. Figure 1.1: La photo de famille des participants de la rencontre de Sebastopol Au termes des deux jours de la rencontre de Sebastopol, les participants ont défini ensemble une série de huit critères pour que des données gouvernementales soient considérées comme ouvertes : - complètes : toutes les données publiques doivent être rendues disponibles dans les limites légales liées à la vie privée ou la sécurité ; primaires : les données ouvertes sont telles que collectées à la source, non-agrégées avec le plus haut niveau de granularité ; fraiches : les données doivent être disponibles dès qu’elles sont produites (timely) ; accessibles : les données doivent être utilisables par le plus grand nombre d’usagers potentiels ; lisibles par les machines : les données peuvent faire l’objet d’un traitement automatisé par les machines ; non discriminatoires : elles peuvent être utilisées par tous sans réclamer un enregistrement préalable ; dans un format ouvert : ce format ne doit pas être la propriété d’une organisation en particulier et doit faire l’objet d’une gouvernance commune par ses usagers ; avec une licence ouverte : les principes de Sebastopol vont plus loin que l’Open Definition en demandant que les données soient placées dans le domaine public. Ces principes sont aujourd’hui encore le fondement de l’open data. Les participants de la rencontre de Sebastopol ont rempli leur objectif, à savoir l’adoption de ces principes par le futur président des États-Unis puisque le 21 janvier 2009, jour de son investiture à la Maison-Blanche, Barack Obama a signé deux mémorandums sur l’Open Government. Le premier exigeait une plus grande coopération des agences gouvernementales aux procédures du Freedom of Information Act (FOIA). Le second réclamait que les agences gouvernementales mettent en œuvre des politiques en faveur de la transparence, la collaboration avec la société civile et la participation des citoyens qui a abouti au lancement en 2009 de data.gov, le premier portail open data national. Aller plus loin : le site OpenGovData.org propose une version annotée des principes de Sebastopol (en anglais). 1.1.3 2008 : “Raw Data Now”, l’appel du fondateur du web à l’ouverture des données brutes Tim Berners-Lee, l’inventeur du web, a formulé son appel à l’ouverture des données brutes le 4 février 2009 à Long Beach en Californie lors d’une conférence TED. TED est un réseau de conférences retransmises gratuitement sur le web qui vise à présenter simplement des idées et à convaincre l’audience de s’impliquer. Dans la vidéo de la conférence dépassant aujourd’hui le million de vue, Tim Berners raconte d’abord son parcours au sein du CERN, l’accélérateur de particules, où il a développé le web pour facilier le partage des documents produits dans son laboratoire. Berners-Lee dit ressentir la même difficulté pour accéder aux données qu’à l’époque de la création avec les documents. Pourtant, les données déterminent une grande partie de nos vies. Il se félicite de la naissance de l’open data et des engagements pris par le président Obama à son arrivée à la Maison Blanche (son discours est intervenu deux mois après la signature des mémorandums) mais il estime que l’ouverture des données implique aussi de transformer les attitudes des administrations. Pour l’inventeur du web, très souvent, les agents publics sont tentés de garder leurs données et trouvent une multitude de raisons pour ne pas les diffuser et permettre leur réutilisation. Dans sa présentation, Berners-Lee a fait référence au médecin suédois Hans Rosling qui a proposé l’expression « database hugging », une métaphore pour décrire une attitude dans laquelle les agents de l’administration s’accrochent à leurs données au point de les « câliner ».Berners-Lee a repris cette métaphore et l’a mimée sur la scène de TED. Figure 1.2: Tim Berners-Lee, lors de sa conférence TED de 2009, mimant le database hugging, l’attitude des administrations qui « s’accrochent » à leurs données Pour l’inventeur du web, les administrations n’arrêtent le database hugging qu’à partir du moment où elles ont présenté leurs données sur un beau site web. Il a demandé d’inverser cette logique et d’abord de fournir les données. Hans appelle ça le database hugging. Vous serrez votre base de données. Vous ne la laissez pas partir tant que vous n’en avez pas fait un joli site web. […] Faites-en donc un joli site. Mais avant cela, donnez-nous accès aux données non altérées. On veut des données. On veut des données non altérées. Il faut que nous demandions des données brutes maintenant. Tim Berners-Lee demande alors au public de la conférence TED de crier « Raw data now! » (“Des données brutes maintenant !”) à l’attention des administrations (figure 1.3). Figure 1.3: Tim Berners-Lee, lors de sa conférence TED de 2009, Tim Berners-Lee appelle le public à crier « raw data now » Ce discours de Tim Berners-Lee a imposé la demande de données brutes comme un aspect essentiel de l’open data avec un slogan facilement mémorisable : ouvrez les données brutes maintenant ! Cette demande de données brutes s’explique par deux choses. D’une part, en ouvrant les données telles qu’elles sont produites, les administrations n’auraient pas à les retravailler, ce qui a été pensé comme un levier pour faciliter l’ouverture. D’autre part, l’obtention des données brutes est pensée comme un moyen de réduire les asymétries d’information entre l’administration et la société civile puisque les données brutes seraient le matériau de l’information publique avec son traitement par l’administration. Aller plus loin : la vidéo de la conférence de Tim Berners-Lee est traduite en français sur le site de TED. ###2010 : le modèle en 5 étoiles, une échelle de l’ouverture des données Après avoir exigé l’ouverture des données brutes, Tim Berners-Lee a appelé à l’utilisation de formats ouverts de données. En 2010, il propose un modèle en cinq étapes, une hiérarchie de la première à la cinquième étoile qui, à la manière de la classification des hôtels, permet aux réutilisateurs de distinguer la qualité des données. Ce modèle s’adressait particulièrement aux gouvernements pour les encourager à adopter le Linked Data pour ouvrir leurs données. Sur la boutique en ligne du W3C, le consortium en charge des standards du web, Berners-Lee vend même des tasses sur lesquelles figure son modèle en cinq étoiles. Il a déclaré espérer que la circulation de ces tasses dans les bureaux inciterait à ouvrir et lier toujours plus de données. Figure 1.4: Tasse du W3C reprenant le modèle en cinq étoiles de Tim Berners-Lee. Dans la hiérarchie de Tim Berners-Lee, les données sont ouvertes dès la validation du premier critère. Il considére que, plus une donnée obtient d’étoiles, plus elle sera simple à utiliser : ⭐ la première étoile demande la publication sur le web des données, quel que soit leur format avec une licence ouverte. ⭐⭐ la deuxième étoile exigeant que les données publiées sur le web sous une licence ouverte soient lisibles par les machines et structurées. ⭐⭐⭐ la troisième étoile réclame la publication des données dans un format non propriétaire. ⭐⭐⭐⭐ pour obtenir la quatrième étoile, les données doivent être publiées dans les standards ouverts du W3C (RDF et SPARQL) qui imposent que les objets contenus dans les données soient décrits. ⭐⭐⭐⭐⭐ la cinquième étoile demande qu’elles soient liées à d’autres données publiées sur le web. Dans les projets d’open data, le modèle de Tim Berners-Lee a été employé essentiellement pour inciter les agents à ouvrir les données dans des formats ouverts comme le CSV plutôt que d’utiliser le format Excel. L’utilisation de formats sémantiques, les deux derniers niveaux du modèle, réclame un travail trop important de transformation des données au regard des moyens généralement alloués aux projets d’open data. Retenons donc du classement en cinq étoiles qu’il suggère aux administrations d’ouvrir les données de manière progressive. En quelque sorte, il leur propose une marche à suivre : d’abord publier les données sur le web avec une licence ouverte, ensuite avec des formats lisibles par les machines puis dans des formats ouverts et enfin éventuellement selon les standards du Linked Data. Aller plus loin : le site 5stardata.info présente en détail le modèle cinq étoiles de Tim Berners-Lee. 1.1.4 2013 : la charte internationale de l’open data, vers l’ouverture par défaut Les 17 et 18 juin 2013 à Loughe-Erne en Irlande du Nord, le Premier ministre britannique, David Cameron, accueillait la réunion du G8, la rencontre de huit chefs d’État parmi les plus grandes puissances économiques mondiales (Allemagne, Canada, États-Unis d’Amérique, France, Royaume-Uni, Italie, Japon, Russie). L’agenda comportait une session sur l’adoption d’une charte sur l’open data. Figure 1.5: Session de travail des membres du G8 en 2013 La charte sur l’open data du G8 a été publiée à la suite du G8 et se compose d’une série de cinq principes et trois annexes. Son préambule détaille les bénéfices de l’open data : création de services, transparence de l’action publique, meilleure gouvernance, amélioration du débat public, lutte contre la corruption, soutien à l’innovation des entreprises et de la société civile, prospérité renouvelée… Cette charte a été par la suite reprise par un groupe qui s’est notamment réuni lors de l’Open Data Conference de 2015 à Ottowa afin de produire une charte internationale de l’open data, dépassant les seuls pays du G8, qui synthétise les grands principes de l’ouverture des données. Elle a été officiellement publiée en octobre 2015 en marge de l’Assemblée Générale des Nations Unies. La charte internationale de l’open data fixe cinq grands principes pour l’ouverture des données : le premier principe donne pour objectif de faire de l’open data la pratique par défaut des administrations pour les données publiques tout en respectant les législations en vigueur sur la propriété intellectuelle et la vie privée. le deuxième principe demande la publication des données en temps opportun (timely) et de manière exhaustive, c’est-à dire en fournissant des données désagrégées et de qualité. le troisième principe réclame des données accessibles et utilisables fournies dans des portails centraux, sans enregistrement préalable, avec une licence ouverte. le quatrième principe demande des données comparables et interopérables fournies dans des formats structurés et normalisés favorisant l’interopérabilité et la réutilisation. le cinquième principe fixe pour objectif à l’open data d’améliorer la gouvernance et d’encourager la participation citoyenne dans la logique de l’ouverture des gouvernements. le sixième principe vise à favoriser le développement inclusif et l’innovation du fait que les données ouvertes donne du pouvoir d’agir à tou·te·s. À travers ce résumé, on voit donc que la charte internationale de l’open data s’inscrit dans la continuité des définitions de l’open data évoquées précédemment. Elle fixe des grands objectifs politiques qui dépassent les textes évoqués précédemment. De ce fait, elle constitue une ressource moins opérationelle pour définir si une donnée est ouverte ou non. Aller plus loin : lire la charte internationale de l’open data en français sur le site OpenDataCharter 1.2 Revue des grands principes de l’ouverture des données Dans la section précédente, nous avons vu les grands moments lors desquels l’open data a été défini. Nous allons maintenant résumer les principes de l’open data en reprenant les dix points définis par la Sunlight Foundation. Il n’y a pas de différence majeure avec les définitions de l’open data évoquées précédemment mais la Sunlight Foundation a réussi à synthétiser l’essentiel dans ce document. Les données doivent être : complètes : elles doivent représenter l’intégralité de ce qui est collecté par l’administration sur un sujet donné avec des métadonnées qui explique comment elles ont été collectées, c’est le principe d’open data par défaut réclamé par la charte internationale de l’open data qui est aujourd’hui la norme en France avec la loi pour une République Numérique ; primaires : les données doivent être non agrégées et telles que collectées à la source, cela équivaut à la demande de données brutes popularisée par Tim Berners-Lee ; fraîches : les données doivent être publiées dès que possible pour garder leur valeur ; accessibles : les données doivent être directement téléchargeables sans enregistrement préalable ; lisibles par les machines : les données doivent être exploitables automatiquement ; accessibles sans discrimination : les usagers doivent pouvoir accéder aux données à tout moment sans s’enregistrer ni fournir de justification ; disponibles sous des formats ouverts : les spécifications de standards de données doivent être ouvertes et, si possible, faire l’objet d’une gouvernance partagée ; disponibles sous licence ouverte : l’Open Definition donne les critères juridiques d’une licence ouverte ; accessibles de façon pérenne en ligne : les données doivent être archivées et les versions précédentes conservées ; sans coût d’utilisation : l’accès et la réutilisation des données doivent être gratuits. Aller plus loin : lire les dix principes définis par la Sunlight Foundation. "],
["partie2.html", "Chapitre 2 Le cadre juridique de l’open data en France 2.1 La loi CADA : accorder aux citoyens un “droit de savoir” 2.2 Du droit d’accès au droit de réutilisation 2.3 Loi pour une République Numérique : l’ouverture des données par défaut", " Chapitre 2 Le cadre juridique de l’open data en France On pourrait croire que l’open data constitue un mouvement récent né il y a près de dix ans. En réalité, les principes internationaux que nous venons de découvrir s’inscrivent dans la continuité du droit français et européen qui garantit la transparence de l’action de l’administration. En plus de porter l’attention sur les données brutes de l’administration, les principes de l’open data ont apporté deux nouveautés : la consécration du droit de réutilisation avec l’apparition de standards internationaux et l’importance de la lisibilité des données par les machines. 2.1 La loi CADA : accorder aux citoyens un “droit de savoir” On peut retracer la philosophie de l’open data dans les fondements même de la République avec la Déclaration des Droits de l’Homme et du Citoyen de 1789 qui dispose dans son article 15 que “la Société a le droit de demander compte à tout Agent public de son administration.” Cet article pose un devoir de reddition de comptes pour l’administration qui s’est exercé pendant longtemps principalement par des institutions comme la Cour des Comptes en charge du contrôle de l’action public. Néanmoins, c’est véritablement à partir de 1978 qu’a émergé un droit d’accès à l’information publique qui s’est progressivement transformé en droit de réutilisation avec le développement d’Internet. Le droit d’accès des citoyens à l’information publique émerge en 1978 avec la loi dite CADA du nom de la Commission d’Accès aux Documents Administrations Administratifs. La France était alors le troisième pays au monde après la Suède en 1766 et les Etats-Unis en 1966 avec le Freedom of Information Act (FOIA) en 1966 à accorder un “droit de savoir” à ses citoyens qui permet de demander aux administrations les informations publiques qu’elles détiennennt. En 1978, c’est un droit d’accès qui est accordé aux citoyens, la priorité à l’époque étant d’améliorer la relation entre l’administration et le public et de renforcer la transparence de l’action publique. La loi CADA donne une définition très large d’un document administratif comme “tous les documents produits ou reçus par l’administration qu’ils se présentent sous forme écrite (dossiers, rapports, études, comptes rendus, procès-verbaux, statistiques, directives, instructions, circulaires…), sous forme d’enregistrement sonore ou visuel ou sous forme numérique ou informatique.” C’est dans ce cadre très générique que s’inscrit l’ouverture des données. Le droit d’accès s’appplique aux documents administratifs produits dans le cadre d’une [mission de service public](de manière directe par les acteurs publics ou indirecte (délégation de service public), c’est-à-dire l’accomplissement de toute activité prise en charge de manière directe par les acteurs publics ou indirecte (délégation de service public) pour satisfaire l’intérêt général et régi par des principes de continuité, d’égalité et d’adptabilité. Enfin, le droit d’accès ne s’exerce que si l’administration a effectivement en sa possession le document demandé, que si le document est formellement achevé et qu’il n’est pas préparatoire à une décision administrative en cours d’élaboration. Sont exclus du droit d’accès les documents administratifs pouvant atteindre porter atteinte à l’exercice des activités régaliennes de l’État et à l’intérêt général. Plusieurs secrets sont protégés notamment concernant les délibérations du Gouvernement, le secret de la défense nationale, la sécurité publique ou encore le déroulement des procédures juridictionnelles. Surtout, le cadre de la loi CADA exclut les données à caractère personnel, relatives à des personnes physiques et permettant leur identification directe ou indirecte. Toutefois, les documents comprenant des données à caractère personnel ne sont communicables et réutilisables que si au moins l’une des trois conditions suivante est remplie : 1. le consentement des personnes concernées a été recueilli après leur bonne information sur la finalité et les modalités de la communication ou de la réutilisation des données les concernant ; 2. les données sont anonymisées (c’est-à-dire non identifiantes ou ne permettant pas, compte tenu de leur niveau d’agrégation, d’identifier à nouveau les personnes concernées) ; 3. la réutilisation est autorisée par un texte législatif ou réglementaire. Aller plus loin : Sur tous ces points, le site de la CADA détaille la jurisprudence, en particulier dans la partie sur l’étendue du droit d’accès. Le guide de demande de données publiques auprès des collectivités produit par Bordeaux Métropole permet aussi de mieux comprendre le cadre légal. 2.2 Du droit d’accès au droit de réutilisation La loi CADA a accordé aux citoyens un droit d’accès aux documents administratifs, la question de la réutilisation des données publiques a émergé dans les années 1990 avec le développement d’Internet facilitant la diffusion des données publiques et le développement de nouveaux services au public. Comme l’explique Boustany (2013), “la différence réside dans les enjeux : l’accès aux documents publics relève de la démocratie et de la transparence des institutions ; la réutilisation des données des données pour produire des services ou pour la connaissance présente des enjeux socio-économiques.” Aller plus loin : lire l’article de Joumana Boustany (2013), « Accès et réutilisation des données publiques : État des lieux en France&quot; dans la revue Les Cahiers du numérique La frise qui suit retrace les principales dates de l’apparition du droit de réutilisation des données, chacune de ces dates étant développée à la suite : + - Le droit de réutilisation des informations publiques a été fortement soutenu par l’Union Européenne en particulier avec la Directive dite PSI (Public Sector Information) de 2003 concernant la réutilisation des informations du secteur public qui fixe les règles minimales et les conditions de réutilisation de ces données publiques. Elle a été transposé en droit français par l’ordonnance du 6 juin 2005 qui autorise les usages commerciaux des données publiques et fixe le cadre de la réutilisation en autorisant notamment le paiement d’une redevance couvrant des frais autre que ceux de la reproduction des documents. En 2013, la révision de la directive PSI a instauré un véritable droit à réutilisation des données du secteur public pour lequel persiste toutefois une exception pour le secteur culturel (musées, bibliothèques, archives). La loi relative à la gratuité et aux modalités de la réutilisation des informations du secteur public, dite loi Valter de 2015, l’a traduit en droit français en instaurant le principe de gratuité généralisé à tous les secteurs, toutefois, les données des services publics industriels et commerciaux restent exclues ce qui a été abrogé par la loi pour une République Numérique que nous détaillerons dans la prochaine section. Aller plus loin : lire le guide “Les lois régulant la donnée publique” produit par Open Data France et la présentation “Quelles obligations réglementaires pour l’ouverture des données?” produite par le SGAR de la région Occitanie dans le cadre du projet Open DataLab Enfin, dernier élément du contexte juridique, la directive européenne Inspire du 14 mars 2007 vise à l’harmonisation et à l’ouverture des données géographiques au niveau européen.Transposée en droit français par l’ordonnance du 21 octobre 2010, elle impose aux autorités publiques de recenser les données qui rentrent dans le périmètre concerné par la directive, de créer et de maintenir les métadonnées selon les normes établies par la commission européenne, de mettre les métadonnées et les données en suivant les standards européens. Pour certaines données qui ne pourraient être ouvertes au public, la directive impose le partage entre autorités publiques. Aller plus loin : lire le document “La directive Inspire pour les néophytes” établi par la Mission de l’information géographique (MIG) du ministère du développement durable en 2016 2.3 Loi pour une République Numérique : l’ouverture des données par défaut Promulguée le 7 octobre 2016, la loi pour une République Numérique a fait l’objet de près de quatre ans d’annonces, de consultations et de débat. Son titre 1 porte sur l’ouverture des données publiques et rend obligatoire la mise à disposition des données publiques communicables. La loi impose un principe d’ouverture des données par défaut à toutes les administrations et collectivités locales de plus de 3500 habitants et 50 agents qui concerne un périmètre très large comprenant les documents communiqués suite à des demandes CADA (depuis le 7 avril 2017), les “bases de données” et les données “dont la publication présente un intérêt économique, social, sanitaire ou environnemental” à partir d’octobre 2018. Rares sont les données publiques qui ne sont donc pas concernées par cette obligation d’ouverture. L’obligation concerne aussi les entreprises délégataires d’une mission de service public pour les données collectées ou produites à l’occasion de l’exploitation du service public faisant l’objet du contrat qui doivent être fournies gratuitement aux acteurs publics, en charge alors de les diffuser. La loi ne prévoit pas de sanctions pour les administrations qui ne respecteraient pas cette obligation. Toutefois, la notion de données qui délimite le périmètre concerné par l’obligation d’ouverture ne fait pas l’objet d’une définition juridique. Classiquement, on définit les données comme une forme de représentation d’une réalité destinée généralement à être traitées par un ordinateur, à l’opposée des informations généralement destinées à être traitées par des humains. Cette définition est une parmi d’autres, la notion de données faisant l’objet de débats dans la littérature sur lequel nous n’allons pas nous étendre ici. Dans le droit, la seule référence que nous connaissons est un arrêté du 22 décembre 1981 relatif à l’enrichissement du vocabulaire informatique définit la donnée comme la « représentation d’une information sous une forme conventionnelle destinée à faciliter son traitement (en anglais : data). » L’absence de définition juridique pourrait devenir problématique dès lors que des contentieux tenteront de faire appliquer l’obligation d’ouverture des données prévus par la loi pour une République numérique. Sur ce point, la loi pour une République Numérique consacre l’utilisation de standards ouverts pour la communication des documents administratifs afin de faciliter la réutilisation des données par les machines L’administration (ministères, collectivités territoriales, établissements publics…) sera dorénavant tenue, lorsqu’elle communique un document administratif au format électronique, de le mettre à disposition du citoyen “dans un standard ouvert, aisément réutilisable et exploitable par un système de traitement automatisé”. Concrètement, cela empêche la publication de fichiers PDF là où un fichier CSV pourrait être diffusé, conformément aux principes internationaux de l’open data évoqué dans la section précédente. Enfin, la loi limite par décret les licences qui peuvent être utilisées par les administrations. Le décret du 27 avril 2017 autorise deux licences : la Licence Ouverte d’Etalab et la licence OpenDataBaseLicense (nous reviendrons à la suite sur le contenu de ces licences). Les administrations qui voudront utiliser une autre licence devront remplir une procédure d’homologation auprès des sercices du Premier ministre qui impose notamment un exposé des motifs ayant conduit conduit à choisir une licence hors de la liste fixée dans le décret et une consultation des usagers affectés par la licence proposée. L’homologation doit être faite pour chaque jeu de données même si la licence reste la même. Aller plus loin : lire l’article “On vous explique le volet « Open Data » de la loi Lemaire” publié par le site NextInpact Ces deux licences offrent un choix aux administrations, la licence ouverte étant plus permissive que la licence ODBL qui a été conçue dans une logique de “pot commun” permettant de garantir que les données resteront ouvertes après leur réutilisation. Figure 2.1: Panorama des licences de données ouvertes (source : Open Data Lab Aller plus loin : le guide &quot;Ouverture des données de la recherche. Guide d’analyse du cadre juridique en France &quot; de l’INRA présente dans sa fiche numéro 6 une comparaison complète de la licence ouverte et de la licence ODBL "],
["partie3.html", "Chapitre 3 Les bénéfices attendus d’une politique d’open data pour une collectivité 3.1 Du point de vue de l’organisation, l’ouverture des données comme un levier d’innovation ouverte 3.2 Du point de vue du système d’information, l’open data comme levier de qualité des données 3.3 Du point de vue du citoyen, l’ouverture des données comme pierre angulaire de l’ouverture des gouvernements 3.4 Du point économique, soutien à la création de services innovants", " Chapitre 3 Les bénéfices attendus d’une politique d’open data pour une collectivité Les bénéfices de l’open data sont souvent résumés à trois dimensions : transparence, innovation et modernisation. Ces trois dimensions sont juste et utiles pour repérer les bénéfices qu’on peut attendre d’une politique open data ambitieuse. Mais ces objectifs génériques peinent à rendre compte de l’utilité immédiate que l’ouverture des données peut procurer aux institutions qui s’engagent dans une démarche d’open data. 3.1 Du point de vue de l’organisation, l’ouverture des données comme un levier d’innovation ouverte Au niveau organisationnel, l’ouverture des données peut être vue comme une manière de valoriser le travail de l’administration. En effet, l’ouverture des données permet de montrer au public la qualité du travail réalisé par les agents et rend visible l’effort d’objectivation des politiques publiques par la donnée. L’ouverture des données peut aussi être un moyen de présenter au public les compétences et les expertises du département. Par exemple, le département de Haute-Garonne présente les jeux de données en cinq catégories à la une du portail qui résume les compétences départementales : solidarités, déplacements, territoire, culture, jeunesse et famille. L’open data est aussi un moyen de motiver les agents, l’ouverture des données permet de servir l’intérêt général dans une logique de service public. Un des arguments les plus fréquents en faveur de l’ouverture des données consiste à dire que l’ouverture des données permet de rendre au public les données qui ont été payé par l’impôt, c’est sous cet angle qu’au Royaume-Uni le Guardian a justifié son appel à l’ouverture des données avec sa campagne en 2006 “rendez nous les joyaux de la couronne !” En France, on peut relier les principes de l’open data aux trois grands principes du service public : - la continuité du service public : dès lors que les données sont ouvertes, elles peuvent continuer à être utiles pour le public même si les services qui s’appuient dessus ont été cloturés comme c’est souvent le cas avec les applications mobiles produites par les acteurs publics ; - l’égalité devant le service public : lorsque les données sont ouvertes, toute personne a un droit égal d’accès et de réutilisation en vertu du principe de non-discrimnination des usagers au coeur de l’open data ; - l’adaptabilité : dès lors que les données sont ouvertes, les citoyens sont en capacité de faire évoluer les services en fonction des besoins des usagers et des évolutions techniques. Par ailleurs, l’open data peut aussi être vu comme un gain de temps lorsque les agents reçoivent de nombreuses demandes de la part d’entreprises et d’acteurs associatifs pour obtenir des données. Leur ouverture permet d’avoir un point centralisé où trouver les données et éviter de renvoyer à de multiples reprises les mêmes données. Aussi, ouvrir les données brutes évite de mettre en forme les données comme c’était souvent le cas avec les fichiers PDF. Par exemple, un agent de la ville de Paris publiait régulièrement des fichiers PDF pour rendre compte du parc de logements sociaux ce qui demandait de découper les données par arrondissement et de mettre en ligne un fichier par arrondissement. Maintenant que les données sont ouvertes, cet agent a juste à publier sa feuille de calcul, son document de travail, sur laquelle les usagers n’ont qu’à utiliser les filtres pour obtenir les données par arrondissement. Toujours d’un point de vue organisationnel, l’open data peut permettre d’ouvrir de nouvelles possibilités de croisement et d’exploitation des données en interne. Une étude interne de la ville de Paris en 2013 a montré que 80% des téléchargements sur le portail open data provenaient des services de la ville. Ouvrir ses données permet de désiloter les services et de faire découvrir déjà aux agents des données dont ils n’avaient pas connaissance. 3.2 Du point de vue du système d’information, l’open data comme levier de qualité des données Au niveau des systèmes d’information, ouvrir des données peut permettre d’améliorer leur qualité. En effet, en exposant les données au public, les propducteurs de données peuvent découvrir des erreurs, des approximations ou des coquilles qui n’ont pas été détectées lorsqu’elles circulaient uniquement à l’intérieur du service. Par exemple, les agents de Keolis Rennes qui ont ouvert des données concernant les horaires des transports publics ont pu découvrir par les retours des usagers que certains arrêts étaient localisés parfois 300m plus loin que ce que les données indiquaient ! En effet, les emplacements des arrêts étaient auparavant collectés pour produire des cartes ; dès lors que les usagers des transports les exploitent dans des applications mobile sur le terrain, la précision de la localisation devient crucial. Ce cas illustre la difficulté avec cette notion de qualité des données qui dépend de la finalité de l’utilisation et des besoins de l’usager. L’ouverture des données peut aussi permettre de mieux connaitre le système d’information et de cartographier des données qui jusqu’alors n’étaient pas identifiées. C’est lors de la phase d’identification des données en amont de l’ouverture que les responsables de projet d’open data découvrent de nouveaux fichiers ou bases qui n’étaient pas alors connues des services auquel ces agents sont rattachés. Par exemple, dans une entreprise, le projet d’open data a permis de relancer un projet de cartographie du système d’information qui était jusqu’alors dormant ; avant de sélectionner les données qu’elles souhaitaient ouvrir, l’entreprise devait d’abord savoir ce dont elle disposait comme données. L’ouverture des données peut servir ainsi à renforcer les projets de cartographie des systèmes d’information en détectant des données stratégiques qui sont gérées dans des progiciels extérieur au système d’information. Dans d’autres cas, les données sont gérées localement dans des feuilles de calcul, parfois sans sauvegarde, alors que les données sont essentielles à la conduite de certaines politiques publiques. Enfin, l’ouverture des données peut révéler certains enjeux liés à la souveraineté du SI. Après avoir décidé d’ouvrir des données, les agents se heurtent fréquemment à des systèmes d’information qui n’ont pas été prévu pour l’ouverture : les données ne sont tout simplement pas exportables, les fonctionnnalités d’exports prévus par les outils ne permettent pas d’obtenir le niveau de détail attendu, il n’est pas possible d’exporter toutes les données… Les projets d’open data mettent ainsi les systèmes d’information à l’épreuve et interrogent la souveraineté de l’institution sur ces données. Dans certains cas, il faut développer des “moulinettes”, des petits outils qui vont permettre de renconstituer la base de données ; dans d’autres, il faut négocier avec des prestataires qui peuvent réclamer le réglement d’une prestation spécificique pour l’ouverture des données. 3.3 Du point de vue du citoyen, l’ouverture des données comme pierre angulaire de l’ouverture des gouvernements L’ouverture des données prend part à un mouvement plus large, celui de l’ouverture des gouvernements (open government) qui postule que la transparence accrue par l’ouverture des données et d’autres mécanismes de réédition des comptes (accountability) permet de renforcer la participation des citoyens et de déveloper la collaboration avec la société civile dans la mise en oeuvre des politiques publiques. Ce schéma de l’association Démocratie Ouverte le résume bien : Figure 3.1: Schéma récapitulatif des principes du gouvernement ouvert Une politique d’open data peut donc ainsi renforcer la transparence de l’action publique. Par rapport aux dispositifs existants, les politiques d’open data permettent aux citoyens d’obtenir des données brutes dans leur plus fort niveau de granularité spatiale et temporelle, c’est-à-dire que les données sont mises à disposition avec le plus haut niveau de détail afin d’aller au plus proche des phénomènes. Par exemple, au lancement de data.gouv.fr en 2011, le ministère de l’intérieur a ouvert les données de la base des accidents en publiant chaque accident avec le détail des véhicules impliqués, la localisation précise et les conséquences pour les victimes là où auparavant on devait se contenter de données agrégées par mois et par département ou commune. Ce jeu de données a connu de très nombreuses réutilisations (recensées sur data.gouv.fr dans la rubrique réutilisation du jeu de données par des journalistes et des chercheurs qui ont pu produire des analyses et des visualisations à un niveau jusqu’alors impossible. L’open data permet ainsi de réduire les asymétries d’information dès lors que les citoyens disposent des mêmes données que l’administration. L’ouverture des données peut aussi permettre de servir la communication de l’institution en s’appuyant sur la visualisation des données. La défiance des citoyens à l’égard des acteurs publics atteignant des records, ouvrir des données et communiquer avec celle-ci peut permettre de prouver ce qui est dit par la communication publique en s’ouvrant à de nouvelles analyses si tant est que les citoyens peuvent bien refaire les calculs avec les données ouvertes. Par exemple, le département de la Gironde a publié un outil pédagogique qui permet d’expliquer comment le budget est utilisé et d’explorer le détail des données qui sont par ailleurs ouvertes sur le portail open data. Les données ouvertes peuvent aussi permettent de suivre les engagements de la mandature. C’est ce qu’a fait la ville d’Issy les Moulineaux avec son rapport financier qui présente avec des visualisations interactives s’appuyant sur des donnés ouvertes l’utilisation des fonds publics. A une autre échelle, le maire de Los Angeles publie un dashboard qui présente les principaux indicateurs de son mandat et signale les domaines dans lesquels des efforts doivent être faits. Enfin, l’ouverture des données peut permettre de mieux impliquer les citoyens notamment dans les démarches de concertation. En disposant des données du débat, les citoyens sont en capacité de mieux comprendre les enjeux de la consultation, de contester les calculs de l’administration et de faire des propositions sur une base factuelle solide. A Toulouse, des ateliers de cartographie citoyenne ont été organisés dans le cadre du débat public sur la nouvelle ligne de métro permettant aux habitants de s’impliquer dans le tracé de la ligne. A Paris, la CAF a organisé des expéditions de données avec l’association Ecole des Données pour consulter les habitants sur ses politiques sur la base de données et en produisant des données. Les citoyens peuvent aussi être impliqués dans la co-prodcution des données elles-même. La ville de Nantes a conçu le projet Cartoquartiers pour que les citoyens puissent cartographier localement les services à leur disposition (recyclage, associations de quartiers, services publics…) afin de mieux valoriser la vie de quartier. 3.4 Du point économique, soutien à la création de services innovants C’est généralement cet enjeu qui a été le plus mieux en avant lors de la définition des premières politiques d’open data. Dans les années 2000, la Commission européenne s’est inspirée du cadre réglementaire états-unien et a multiplié les études sur le potentiel économique de la réutilisation de l’information publique, évaluant jusqu’à 200 milliards d’euros par an la valeur de leur circulation optimale dans les pays de l’Union. La promesse de découvrir des gisements de croissance encore inexploités et donc de développer des recettes fiscales associées a impulsé les premiers projets d’open data. Il faut aussi rappeller que l’open data est apparu dans le débat public aux alentours de 2007, en même temps que le développement de l’économie des apps avec le lancement des boutiques d’applications sur smartphone (Apple AppStore, Google PlayStore…) qui ont permis une vague de création de services et d’emploi dans le développement informatique. Il était donc espéré que les données ouvertes soient le carburant de cette nouvelle économie. En la matière, les résultats ont été plutôt décevants, une déception à la hauteur des promesses vertigineuses formulées par les cabinets de conseil et certaines institutions comme l’Union Européenne qui, dans un récent rapport, a réévalué à 320 milliards d’euros le marché direct et indirect des données ouvertes dans les 28 pays membres pour la période 2016-2020. Lorsqu’on consulte les données qualitatives de l’Open Data Barometer, classement qui interroge pays par pays l’impact des données ouvertes, les indices de cette création de valeur sont beaucoup plus difficiles à identifier ; l’Open Data Barometer n’a pu identifier en France en 2016 que 8 sociétés employant entre 5 et 30 personnes dont les données ouvertes sont au coeur du modèle économique. Toutefois, il ne faut pas non plus se polariser sur les créations d’entreprise découlant directement des politiques d’open data : de nombreuses entreprises ont recours à des données ouvertes dans leurs outils internes ou dans leurs produits sans qu’elles soient détectées du fait que les principes de l’open data imposent de ne pas exiger d’inscription. La plupart des usagers de l’open data passent sous le radar ! Pour une collectivité locale, il semble irréaliste de poser en condition la création d’emplois directs à un projet d’ouverture de données. Néanmoins, dès lors que les collectivités ouvrent leurs données de manière concertée si possible en utilisant un standard de données commun comme le préconise l’association Open Data France avec son socle commun de données locales, un marché peut s’ouvrir aux entreprises locales. Par exemple, à Rennes, le concours open data en 2011 a permis l’émergence d’Handimap une application mobile qui permet de calculer des itinéraires accessibles pour les personnes à mobilité réduite. Le service est aujourd’hui disponible dans 5 villes en France. Toujours dans le domaine de la mobilité, l’application J’accède permet d’identifier les lieux accessibles aux personnes à mobilité réduite. Autour des données relatives aux menus des cantines scolaires, QuiDitMiam permet aux parents de disposer d’une application mobile pour connaitre ce que leurs enfants mangent à l’école aujourd’hui. Née à Toulouse, l’application est maintenant disponible dans une quizaine de villes en France et continue son expansion. Figure 3.2: Aperçu de Quiditmiam Enfin, c’est surtout dans le domaine des transports où un standard, le GTFS développé au départ par Google, que les exemples de service innovants sont les plus nombreux avec des applications aujourd’hui utilisées par plusieurs dizaines de millions d’utilisateurs dans le monde comme Moovit, Transit ou Citymapper. "],
["partie4.html", "Chapitre 4 Les facteurs clés de succès d’une politique d’open data 4.1 Obtenir un soutien au plus haut niveau 4.2 Configurer l’organisation pour l’ouverture des données 4.3 Faciliter la découverte et l’utilisation des données 4.4 Rester à l’écoute et interagir avec les usagers", " Chapitre 4 Les facteurs clés de succès d’une politique d’open data Dans cette section, nous allons essayer de résumer les facteurs de succès d’une politique d’open data en nous appuyant principalement sur trois sources librement réutilisables. Tout d’abord, l’outil d’évaluation de l’état de préparation d’une politique d’open data élaboré par la Banque Mondiale en amont de projets d’ouverture de données. Même s’ils sont plus adaptés pour des contextes nationaux, les critères de cet outil de positionnement ont été revus par une communauté mondiale ce qui en fait une source de référence. Nous nous appuyons aussi sur la checklist des 72 règles destinées aux producteurs de données réalisée par Opquast. Elle propose des critères précis qui servent à évaluer un portail open data et les jeux de données qu’ils contiennent. Chaque critère comprend le détail de l’objectif, de la solution technique pour s’y conformer et le moyen d’évaluation. Enfin, la check-list des prérequis pour se lancer dans l’OpenData établie par le projet OpenDataLab de la préfecture de région Occitanie permet de mesurer ses points forts et faibles en amont d’une démarche d’ouverture de données. La feuille de calcul proposée dans le kit pour les collectivités permet d’obtenir une visualisation sous forme de matrice pour mesurer la préparation d’une organisation sur le pilotage, l’organisation, l’ouverture des données, l’engagement citoyen, l’animation de l’écosystème et le retour sur investissement. Ces trois outils ont en commun d’offrir un cadre d’analyse pour déterminer si les conditions sont réunies pour une politique d’open data réussie. Chaque configuration administrative et politique étant différente, ces recommandations doivent être adaptées au contexte de chaque institution. On peut synthétiser ces recommandations en quatre facteurs principaux : obtenir un soutien au plus haut niveau configurer l’organisation pour l’ouverture faciliter la découverte et l’utilisation des données rester à l’écoute et interagir avec les usagers 4.1 Obtenir un soutien au plus haut niveau Le soutien politique au plus haut niveau est la condition sine qua none sans laquelle une politique d’open data ne peut être enclenchée et réussie. Les projets d’ouverture des données publiques font souvent face à des résistances liées d’une part aux obligations de protection des données qui incombent aux agents, et d’autre part au fait que certaines personnes (à l’intérieur comme à l’extérieur des administrations)ont toujours bénéficié d’un accès privilégié à l’information et aux données. Il est donc important d’avoir un soutien politique fort et durable pour surmonter ces résistances et assumer les risques politiques (et autres) induits par l’ouverture des données. L’engagement doit être affirmé au plus haut niveau politique et présenté publiquement. Si possible, cet engagement pourra être renforcé par un vote de l’assemblée compétente (le conseil départemental dans notre cas) dans une délibération qui exposera les ambitions et les moyens mis en oeuvre. C’est ce qu’ont fait par exemple la ville de Nantes et le département du Gers. Au delà d’un engagement politique, il peut être utile de communiquer auprès du public sur les ambitions de l’institution en matière d’ouverture des données. Cela nécessite en préalable de mettre en place un plan stratégique dans laquelle l’organisation décline les objectifs qu’elle attribue à l’ouverture des données et affiche ses ambitions. Par exemple, la région Ile-de-France s’est fixée pour objectif, avant même l’adoption de la loi pour une République numérique, de parvenir à l’open data par défaut. Le conseil régional a adopté un rapport qui, pour atteindre cet objectif, impose aux administrations une règle « appliquer ou expliquer » : les données doivent être ouvertes par défaut ou l’administration concernée doit rendre compte des raisons pour lesquelles elles ne le sont pas. Un plan stratégique doit aussi afficher un calendrier et des priorités : par exemple, la région PACA dans sa feuille de route stratégique Open Data indique 28 pistes d’actions réparties sur la période 2015-2017 et organisées en deux niveaux de priorité. Il faut aussi penser la gouvernance pour que l’exécution du plan soit suivie. À ce titre, la feuille de route de la région PACA évoquée précédemment organise la gouvernance du projet entre deux niveaux : un comité de pilotage composé d’élus et de cadres dirigeants de l’administration régionale et un groupe de travail qui comporte toutes les organisations contributrices et des invités issus de la société civile locale. Enfin, cette feuille de route stratégique doit inclure un budget défini et provisionné avec des ressources, notamment financières, pour soutenir le développement de services. Figure 4.1: La feuille de route du plan stratégique de la région PACA 4.2 Configurer l’organisation pour l’ouverture des données Ouvrir des données, c’est aussi ouvrir l’administration. Ce changement de paradigme implique de repenser le fonctionnement de l’organisation pour se préparer à ouvrir des données qui, pour certaines, n’avaient jusqu’alors pas fait l’objet d’une diffusion publique. Un projet d’open data doit d’abord avoir un·e chef d’orchestre. Le responsable de projet open data est un agent qui, si possible, connait bien le fonctionnement de l’institution, a déjà coordonné ou pris part à un projet transversal et dispose d’un soutien politique et administratif important. Le rôle du chef de projet est de coordonner tous les acteurs qui interviennent dans l’ouverture des données, de relancer les producteurs de données, de s’assurer de la qualité des données et de faire le lien avec les réutilisateurs. Le·la responsable de projet ne doit toutefois pas être la seule cheville ouvrière d’un projet open data, tout ne doit pas reposer sur elle ou lui. Il est important que les responsabilités soient partagées et clairement définies en structurant un réseau dans l’institution. La configuration la plus couramment adoptée dans les collectivités locales est celle d’un réseau de correspondants qui reprend la solution adoptée par l’Etat pour organiser le recensement des données publiques. Les correspondants sont les interlocuteurs privilégiés du responsable de projet : ils lui indiquent les données publiques ouvrables, le présentent auprès des producteurs de données et peut coordonner directement l’ouverture de certains jeux de données. Dans certaines institutions, cette configuration peut être toutefois trop lourde. On privilégiera alors une structuration du réseau plus informelle qui pourra, au fur et à mesure des échanges avec les agents, se formaliser pour que l’ouverture des données entre dans les missions des agents impliqués ce qui facilitera l’articulation avec leurs activités ordinaires. Sur le volet organisationnel, il faudra aussi prévoir au moins un organe de contrôle. Cet organe de contrôle peut être dans certains cas divisé entre un comité technique composé d’agents, qui déterminera les orientations du projet d’open data (création du portail, sélection des jeux de données à ouvrir en priorité, choix d’une licence, communication…) et d’un comité de pilotage composé d’élus et de cadres dirigeants de l’administration qui auront à faire les arbitrages notamment lorsque l’ouverture d’un jeu de données se heurte à des résistances politiques, administratives ou techniques. En effet, si le mandat est clair, les agents pourront dédier du temps à l’ouverture des données et pourront ouvrir sans difficultés des données jusqu’alors jugées « sensibles ». Enfin, il peut être utile de cartographier les soutiens et les résistances à la démarche d’ouverture des données. Le projet OpenDataLab préconise en amont de l’ouverture des données d’identifier les soutiens de la démarche avec un pouvoir suffisant, d’identifier les résistances et de prévoir des leviers pour les surmonter. 4.3 Faciliter la découverte et l’utilisation des données Si l’on se fie aux deux classements internationaux de référence en matière d’open data, l’Open Data Barometer de la Web Foundation et l’Open Data Index d’Open Knowledge, les projets d’ouverture de données font face à deux écueils majeurs : la découvrabilité et la qualité des données. Concernant le premier point, il est courant d’entendre des usagers de données ouvertes déclarer qu’ils ont les plus grandes difficultés à trouver les données qu’ils/elles cherchent. Par exemple, Jules Grandin journaliste au Monde racontait récemment dans un tweet la « déception en 4 actes » de sa recherche de données sur la fréquentation des stations de RER en région parisienne. Après une recherche Google, un jeu de données sur data.gouv.fr intitulé « comptage voyageur sur RER » lui est proposé en premier résultat. Quand il télécharge le fichier, celui ne fait qu’une ligne et deux colonnes indiquant le nombre de voyageurs sur la ligne 0. Ce cas est révélateur de l’expérience courante et souvent décevante des usagers de données ouvertes. D’une part, les données ouvertes sont encore l’exception mais, quand elles sont ouvertes, il est très difficile de les localiser. Par exemple, le moteur de recherche de data.gouv.fr renvoie rarement vers les données qu’on cherche, c’est ce qu’a révélé une étude auprès des utilisateurs du portail réalisée par Thomas Parisot pour Etalab : tapez «élections » sur data.gouv.fr et vous trouverez plus de 650 jeux de données dont beaucoup ne sont pertinents que localement. Ainsi, pour l’Open Data Index, la question de la découvrabilité (findability) des données est un prérequis pour que l’open data remplisse son potentiel mais, à l’heure actuelle, la plupart des données sont très dures à localiser. Pour faciliter la découverte des données, on pourra d’abord s’assurer que les métadonnées soient complètes et décrivent correctement le jeu de données. Selon une étude récente réalisée par Datactivist sur les catalogues de données de 15 villes en France, seuls 4 % des jeux de données ont une description qui dépasse les 1000 caractères soit moins d’une demi-page A4. Difficile dans ces conditions de trouver les données et de comprendre ce qu’elles contiennent. On pourra aussi s’assurer que les jeux de données ne sont pas référencés uniquement sur le portail open data. Une mesure simple mais rarement entreprise consiste à s’assurer que le site de l’institution renvoie vers les jeux de données présents sur le portail. Dans une page sur les subventions aux associations, pourquoi ne pas renvoyer vers le jeu de données qui présente les subventions attribuées les années précédentes ? Enfin, il est important de s’assurer que le portail s’adresse à un large public et pas uniquement aux usagers habituels des données. Par exemple, il n’est expliqué nulle part sur data.gouv.fr comment ouvrir un fichier CSV même si, en France, la plupart des fichiers CSV utilisent le point-virgule et non la virgule (utilisée par défaut à l’étranger) pour séparer les valeurs. Cela demande souvent de changer le paramétrage du tableur ce qui peut dérouter de nombreux usagers. Pour éviter que les données ne s’adressent qu’à celles et ceux qui les manipulent au quotidien, on pourra entreprendre un travail de définition de personas comme l’a fait la ville de New York avec le projet « meet the users of open data. » Figure 4.2: Les personas définis par la ville de New York pour son projet Concernant la qualité des données, l’Open Data Barometer a soulevé cet enjeu dans son quatrième rapport : « Les données publiques sont souvent incomplètes, périmées, de mauvaise qualité et fragmentées. Dans la plupart des cas, les portails et les catalogues de données ouvertes sont alimentés manuellement résultant d’approches informelles de gestion des données. Les procédures, les échéances et les responsabilités sont fréquemment obscures parmi les institutions gouvernementales en charge de ce travail. » Il en résulte que, bien souvent, les données sont souvent inutilisables par manque de granularité temporelle et spatiale, l’absence de mise à jour, par une documentation qui ne permet pas de comprendre comment les données ont été produites et ce qu’elles décrivent. Ces problèmes de qualité ne concernent pas que les administrations pour lesquelles la diffusion de données est inédite, on retrouve ces problèmes pour certaines organisations dont la production de données constitue le cœur de l’activité. Par exemple, un usager des données ouvertes a listé dans un billet de blog les problèmes qu’il a rencontrés avec les données ouvertes d’Infogreffe. Son billet décrit de nombreux problèmes auquel l’usager doit faire face : des colonnes qui disparaissent, sont créées ou renommées au fil des années, des colonnes “parasites” dont le nommage ou la documentation ne permettent pas de savoir ce qu’elles contiennent, des jeux de données annualisés qui contiennent plusieurs années de données, des colonnes en doublon, des coordonnées géographiques fausses, une documentation quasi inexistante… Pour éviter ces problèmes, on pourra s’appuyer sur la méthodologie du sprint qualité élaboré par la Fondation Internet Nouvelle Génération (FING) dans le cadre du projet Infolab. Cette méthodologie propose une centaine de points de contrôle pour s’assurer de la qualité d’un jeu de données. Pour une approche plus rapide, il peut être utile de faire un contrôle rapide des jeux de données (ce que les data scientists appellent un « sanity check  ») en utilisant un outil simple comme WTF CSV qui permet de prévisualiser le contenu d’un jeu de données et donne un résumé des valeurs extrêmes et manquantes pour chaque colonne. Figure 4.3: WTFCSV permet de prévisualiser le contenu des données 4.4 Rester à l’écoute et interagir avec les usagers Les projets d’open data constituent généralement des politiques de l’offre dans lesquelles l’administration décide quelles données ouvrir, ce qu’elles contiennent, quand les ouvrir et les mettre à jour. Pour s’efforcer à résoudre les problèmes évoqués dans la section précédente, il nous parait important de nous orienter vers des projets d’open data qui consacrent la demande déjà dans la sélection des données à ouvrir mais aussi qui impliquent les usagers tout au long de l’ouverture des données. Cela implique d’abord de mettre en place des moyens d’échange. La plupart des portails d’open data prévoient une fonctionnalité de commentaires et de discussions ; or, celle-ci est rarement activée souvent par crainte de ne pas être en mesure de traiter les demandes. Ne pas ouvrir les discussions, c’est se priver de la possibilité d’améliorer ses données par les retours des usagers, un des bénéfices majeurs de l’ouverture des données. Il faut aussi mettre en place une procédure pour le traitement des commentaires et former les agents à traiter les demandes même si la réponse ne peut pas toujours satisfaire le citoyen. Il est recommandé que les questions et les réponses soient publiques (on pourra s’inspirer des discussions de la communauté sur data.gouv.fr) pour que les usagers qui rencontrent le même problème avec un jeu de données puissent, d’une part, interagir entre eux pour trouver une solution et, d’autre part, consulter la réponse de l’administration sans reposer la même question. On pourra aussi avoir recours aux réseaux sociaux pour obtenir les retours des usagers. Il peut être utile d’ouvrir un compte dédié ce qui permet d’éviter d’utiliser ses comptes personnels en tant qu’agent et de ne pas interférer avec les messages du compte principal de l’institution. Le travail d’animation territoriale constitue un autre facteur de succès de la médiation des données ouvertes. Cela commence par un travail de qualification de la demande de données provenant de la société civile et des médias et de cartographie des « champions » et des promoteurs de l’ouverture des donnés au niveau du territoire. Il peut être utile de développer des partenariats avec des organismes usagers de données pour les encourager à promouvoir la démarche et à exploiter les nouvelles données ouvertes. L’animation du réseau peut ainsi prendre des formes très variées : organisations d’évènements type hackathon ou open data camp, meetups dans lesquels producteurs et réutilisateurs de données se rencontrent, défis de réutilisation de données, ateliers de médiation dans lesquels un public sans compétence technique en la matière est accompagné dans la réutilisation de données… "]
]
